# Client -> ModelGate auth
MODELGATE_TOKEN=change-me

# Route strategy:
# - If model starts with "ollama/" -> Ollama
# - Else -> DEFAULT_PROVIDER
DEFAULT_PROVIDER=ollama

# When ModelGate runs in Docker on macOS, use host.docker.internal to reach the host machine.
# Ollama is running on the Mac mini host (LaunchDaemon), listening on 11434.
OLLAMA_BASE_URL=http://host.docker.internal:11434/v1

# Optional: OpenAI (only if you later enable it)
OPENAI_API_KEY=
OPENAI_BASE_URL=https://api.openai.com/v1

TIMEOUT_SECONDS=120
